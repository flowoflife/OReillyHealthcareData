{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You can scale your data or normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# generally scaling your data means conforming that data to have a range from 0 to 1\n",
    "# however in sklearn this actually NORMALIZES your data, which is more robust to outliers\n",
    "df = pd.read_csv('daily_activities_and_happiness.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>daily_minutes_hobby</th>\n",
       "      <th>daily_minutes_exercise</th>\n",
       "      <th>daily_minutes_grooming</th>\n",
       "      <th>daily_minutes_commuting</th>\n",
       "      <th>daily_minutes_tv</th>\n",
       "      <th>daily_minutes_talking_to_friend</th>\n",
       "      <th>happiness_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>95</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>72</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>53</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>38</td>\n",
       "      <td>36</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   daily_minutes_hobby  daily_minutes_exercise  daily_minutes_grooming  \\\n",
       "0                   19                      16                      14   \n",
       "1                   17                      23                       8   \n",
       "2                   20                      21                      18   \n",
       "3                   23                      21                      20   \n",
       "4                   28                       7                      19   \n",
       "\n",
       "   daily_minutes_commuting  daily_minutes_tv  daily_minutes_talking_to_friend  \\\n",
       "0                       20                95                               22   \n",
       "1                       64                72                               14   \n",
       "2                       53                30                               18   \n",
       "3                       65                22                               15   \n",
       "4                       38                36                               14   \n",
       "\n",
       "   happiness_rating  \n",
       "0                 2  \n",
       "1                 1  \n",
       "2                 2  \n",
       "3                 2  \n",
       "4                 2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;34m@\u001b[0m\u001b[0m_deprecate_positional_args\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;32mdef\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Standardize a dataset along any axis.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Center to the mean and component wise scale to unit variance.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Read more in the :ref:`User Guide <preprocessing_scaler>`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Parameters\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    X : {array-like, sparse matrix} of shape (n_samples, n_features)\u001b[0m\n",
       "\u001b[0;34m        The data to center and scale.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    axis : int, default=0\u001b[0m\n",
       "\u001b[0;34m        axis used to compute the means and standard deviations along. If 0,\u001b[0m\n",
       "\u001b[0;34m        independently standardize each feature, otherwise (if 1) standardize\u001b[0m\n",
       "\u001b[0;34m        each sample.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    with_mean : bool, default=True\u001b[0m\n",
       "\u001b[0;34m        If True, center the data before scaling.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    with_std : bool, default=True\u001b[0m\n",
       "\u001b[0;34m        If True, scale the data to unit variance (or equivalently,\u001b[0m\n",
       "\u001b[0;34m        unit standard deviation).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    copy : bool, default=True\u001b[0m\n",
       "\u001b[0;34m        set to False to perform inplace row normalization and avoid a\u001b[0m\n",
       "\u001b[0;34m        copy (if the input is already a numpy array or a scipy.sparse\u001b[0m\n",
       "\u001b[0;34m        CSC matrix and if axis is 1).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Returns\u001b[0m\n",
       "\u001b[0;34m    -------\u001b[0m\n",
       "\u001b[0;34m    X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)\u001b[0m\n",
       "\u001b[0;34m        The transformed data.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Notes\u001b[0m\n",
       "\u001b[0;34m    -----\u001b[0m\n",
       "\u001b[0;34m    This implementation will refuse to center scipy.sparse matrices\u001b[0m\n",
       "\u001b[0;34m    since it would make them non-sparse and would potentially crash the\u001b[0m\n",
       "\u001b[0;34m    program with memory exhaustion problems.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Instead the caller is expected to either set explicitly\u001b[0m\n",
       "\u001b[0;34m    `with_mean=False` (in that case, only variance scaling will be\u001b[0m\n",
       "\u001b[0;34m    performed on the features of the CSC matrix) or to call `X.toarray()`\u001b[0m\n",
       "\u001b[0;34m    if he/she expects the materialized dense array to fit in memory.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    To avoid memory copy the caller should pass a CSC matrix.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    NaNs are treated as missing values: disregarded to compute the statistics,\u001b[0m\n",
       "\u001b[0;34m    and maintained during the data transformation.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    We use a biased estimator for the standard deviation, equivalent to\u001b[0m\n",
       "\u001b[0;34m    `numpy.std(x, ddof=0)`. Note that the choice of `ddof` is unlikely to\u001b[0m\n",
       "\u001b[0;34m    affect model performance.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    For a comparison of the different scalers, transformers, and normalizers,\u001b[0m\n",
       "\u001b[0;34m    see :ref:`examples/preprocessing/plot_all_scaling.py\u001b[0m\n",
       "\u001b[0;34m    <sphx_glr_auto_examples_preprocessing_plot_all_scaling.py>`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    .. warning:: Risk of data leak\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Do not use :func:`~sklearn.preprocessing.scale` unless you know\u001b[0m\n",
       "\u001b[0;34m        what you are doing. A common mistake is to apply it to the entire data\u001b[0m\n",
       "\u001b[0;34m        *before* splitting into training and test sets. This will bias the\u001b[0m\n",
       "\u001b[0;34m        model evaluation because information would have leaked from the test\u001b[0m\n",
       "\u001b[0;34m        set to the training set.\u001b[0m\n",
       "\u001b[0;34m        In general, we recommend using\u001b[0m\n",
       "\u001b[0;34m        :class:`~sklearn.preprocessing.StandardScaler` within a\u001b[0m\n",
       "\u001b[0;34m        :ref:`Pipeline <pipeline>` in order to prevent most risks of data\u001b[0m\n",
       "\u001b[0;34m        leaking: `pipe = make_pipeline(StandardScaler(), LogisticRegression())`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    See Also\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    StandardScaler : Performs scaling to unit variance using the Transformer\u001b[0m\n",
       "\u001b[0;34m        API (e.g. as part of a preprocessing\u001b[0m\n",
       "\u001b[0;34m        :class:`~sklearn.pipeline.Pipeline`).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'the scale function'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'allow-nan'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mwith_mean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"Cannot center sparse matrices: pass `with_mean=False` instead\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\" See docstring for motivation and alternatives.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can only scale sparse matrix on axis=0, \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                             \u001b[0;34m\" got axis=%d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mwith_std\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_variance_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_handle_zeros_in_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0minplace_column_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mwith_mean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmean_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mwith_std\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mscale_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Xr is a view on the original array that enables easy use of\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# broadcasting on the axis in which we are interested in\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mXr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mwith_mean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mXr\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mmean_\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmean_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# Verify that mean_1 is 'close to zero'. If X contains very\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# large values, mean_1 can also be very large, due to a lack of\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# precision of mean_. In this case, a pre-scaling of the\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# concerned feature is efficient, for instance by its mean or\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# maximum.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Numerical issues were encountered \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                              \u001b[0;34m\"when centering the data \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                              \u001b[0;34m\"and might not be solved. Dataset may \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                              \u001b[0;34m\"contain too large values. You may need \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                              \u001b[0;34m\"to prescale your features.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mXr\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mmean_1\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mwith_std\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mscale_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_handle_zeros_in_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mXr\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mwith_mean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mmean_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# If mean_2 is not 'close to zero', it comes from the fact that\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# scale_ is very small so that mean_2 = mean_1/scale_ > 0, even\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# if mean_1 was close to zero. The problem is thus essentially\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# due to the lack of precision of mean_. A solution is then to\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# subtract the mean again:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Numerical issues were encountered \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                  \u001b[0;34m\"when scaling the data \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                  \u001b[0;34m\"and might not be solved. The standard \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                  \u001b[0;34m\"deviation of the data is probably \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                  \u001b[0;34m\"very close to 0. \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mXr\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mmean_2\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/.local/share/virtualenvs/projects-WYcKQENt/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scale??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Think about extracting data from irregular\n",
    "# and heterogenous time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from numpy.random import poisson, randint, choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  6,  9,  6,  5,  5, 10,  4,  5,  1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poisson(lam=5, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dates = []\n",
    "user_vals = []\n",
    "possible_indices = list(range(10))\n",
    "for _ in range(10):\n",
    "    dates = pd.date_range('2017-06-11', periods=10, freq='d')\n",
    "    num_indices = randint(low=1, high=10)\n",
    "    indices = choice(a=possible_indices, size=num_indices, replace=False)\n",
    "    use_dates = dates[sorted(indices)]\n",
    "    use_vals = poisson(lam=10, size=num_indices)\n",
    "    user_dates.append(use_dates)\n",
    "    user_vals.append(use_vals)\n",
    "\n",
    "df = pd.DataFrame({'dates': user_dates,\n",
    "                   'vals': user_vals})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dates</th>\n",
       "      <th>vals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DatetimeIndex(['2017-06-11', '2017-06-12', '20...</td>\n",
       "      <td>[11, 16, 12, 11, 10, 11, 12, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DatetimeIndex(['2017-06-11', '2017-06-12', '20...</td>\n",
       "      <td>[13, 6, 7, 9, 12, 10, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DatetimeIndex(['2017-06-12', '2017-06-13', '20...</td>\n",
       "      <td>[10, 10, 7, 13, 11, 12, 8, 10, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DatetimeIndex(['2017-06-13', '2017-06-20'], dt...</td>\n",
       "      <td>[7, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DatetimeIndex(['2017-06-18'], dtype='datetime6...</td>\n",
       "      <td>[10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DatetimeIndex(['2017-06-12', '2017-06-13', '20...</td>\n",
       "      <td>[7, 15, 9, 9, 13, 10, 11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DatetimeIndex(['2017-06-13', '2017-06-14', '20...</td>\n",
       "      <td>[5, 8, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DatetimeIndex(['2017-06-11', '2017-06-12', '20...</td>\n",
       "      <td>[15, 7, 13, 8, 8, 8, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DatetimeIndex(['2017-06-11', '2017-06-16', '20...</td>\n",
       "      <td>[3, 11, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DatetimeIndex(['2017-06-12', '2017-06-19'], dt...</td>\n",
       "      <td>[16, 8]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               dates  \\\n",
       "0  DatetimeIndex(['2017-06-11', '2017-06-12', '20...   \n",
       "1  DatetimeIndex(['2017-06-11', '2017-06-12', '20...   \n",
       "2  DatetimeIndex(['2017-06-12', '2017-06-13', '20...   \n",
       "3  DatetimeIndex(['2017-06-13', '2017-06-20'], dt...   \n",
       "4  DatetimeIndex(['2017-06-18'], dtype='datetime6...   \n",
       "5  DatetimeIndex(['2017-06-12', '2017-06-13', '20...   \n",
       "6  DatetimeIndex(['2017-06-13', '2017-06-14', '20...   \n",
       "7  DatetimeIndex(['2017-06-11', '2017-06-12', '20...   \n",
       "8  DatetimeIndex(['2017-06-11', '2017-06-16', '20...   \n",
       "9  DatetimeIndex(['2017-06-12', '2017-06-19'], dt...   \n",
       "\n",
       "                                vals  \n",
       "0   [11, 16, 12, 11, 10, 11, 12, 14]  \n",
       "1           [13, 6, 7, 9, 12, 10, 8]  \n",
       "2  [10, 10, 7, 13, 11, 12, 8, 10, 9]  \n",
       "3                             [7, 5]  \n",
       "4                               [10]  \n",
       "5          [7, 15, 9, 9, 13, 10, 11]  \n",
       "6                          [5, 8, 3]  \n",
       "7            [15, 7, 13, 8, 8, 8, 9]  \n",
       "8                         [3, 11, 6]  \n",
       "9                            [16, 8]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2017-06-12', '2017-06-13', '2017-06-14', '2017-06-15',\n",
       "               '2017-06-16', '2017-06-17', '2017-06-18', '2017-06-19',\n",
       "               '2017-06-20'],\n",
       "              dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[2]['dates']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Think about how you might characterize these individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high use/ low use individuals\n",
    "df['usage_val'] = df.vals.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dates</th>\n",
       "      <th>vals</th>\n",
       "      <th>usage_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DatetimeIndex(['2017-06-11', '2017-06-12', '20...</td>\n",
       "      <td>[11, 16, 12, 11, 10, 11, 12, 14]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DatetimeIndex(['2017-06-11', '2017-06-12', '20...</td>\n",
       "      <td>[13, 6, 7, 9, 12, 10, 8]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DatetimeIndex(['2017-06-12', '2017-06-13', '20...</td>\n",
       "      <td>[10, 10, 7, 13, 11, 12, 8, 10, 9]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DatetimeIndex(['2017-06-13', '2017-06-20'], dt...</td>\n",
       "      <td>[7, 5]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DatetimeIndex(['2017-06-18'], dtype='datetime6...</td>\n",
       "      <td>[10]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               dates  \\\n",
       "0  DatetimeIndex(['2017-06-11', '2017-06-12', '20...   \n",
       "1  DatetimeIndex(['2017-06-11', '2017-06-12', '20...   \n",
       "2  DatetimeIndex(['2017-06-12', '2017-06-13', '20...   \n",
       "3  DatetimeIndex(['2017-06-13', '2017-06-20'], dt...   \n",
       "4  DatetimeIndex(['2017-06-18'], dtype='datetime6...   \n",
       "\n",
       "                                vals  usage_val  \n",
       "0   [11, 16, 12, 11, 10, 11, 12, 14]          8  \n",
       "1           [13, 6, 7, 9, 12, 10, 8]          7  \n",
       "2  [10, 10, 7, 13, 11, 12, 8, 10, 9]          9  \n",
       "3                             [7, 5]          2  \n",
       "4                               [10]          1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how long was the 'user lifetime'?\n",
    "df['user_lifetime'] = df.dates.apply(lambda x: max(x) - min(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dates</th>\n",
       "      <th>vals</th>\n",
       "      <th>usage_val</th>\n",
       "      <th>user_lifetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DatetimeIndex(['2017-06-11', '2017-06-12', '20...</td>\n",
       "      <td>[11, 16, 12, 11, 10, 11, 12, 14]</td>\n",
       "      <td>8</td>\n",
       "      <td>9 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DatetimeIndex(['2017-06-11', '2017-06-12', '20...</td>\n",
       "      <td>[13, 6, 7, 9, 12, 10, 8]</td>\n",
       "      <td>7</td>\n",
       "      <td>7 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DatetimeIndex(['2017-06-12', '2017-06-13', '20...</td>\n",
       "      <td>[10, 10, 7, 13, 11, 12, 8, 10, 9]</td>\n",
       "      <td>9</td>\n",
       "      <td>8 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DatetimeIndex(['2017-06-13', '2017-06-20'], dt...</td>\n",
       "      <td>[7, 5]</td>\n",
       "      <td>2</td>\n",
       "      <td>7 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DatetimeIndex(['2017-06-18'], dtype='datetime6...</td>\n",
       "      <td>[10]</td>\n",
       "      <td>1</td>\n",
       "      <td>0 days</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               dates  \\\n",
       "0  DatetimeIndex(['2017-06-11', '2017-06-12', '20...   \n",
       "1  DatetimeIndex(['2017-06-11', '2017-06-12', '20...   \n",
       "2  DatetimeIndex(['2017-06-12', '2017-06-13', '20...   \n",
       "3  DatetimeIndex(['2017-06-13', '2017-06-20'], dt...   \n",
       "4  DatetimeIndex(['2017-06-18'], dtype='datetime6...   \n",
       "\n",
       "                                vals  usage_val user_lifetime  \n",
       "0   [11, 16, 12, 11, 10, 11, 12, 14]          8        9 days  \n",
       "1           [13, 6, 7, 9, 12, 10, 8]          7        7 days  \n",
       "2  [10, 10, 7, 13, 11, 12, 8, 10, 9]          9        8 days  \n",
       "3                             [7, 5]          2        7 days  \n",
       "4                               [10]          1        0 days  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# what was the range of values a user input?\n",
    "df['range_values'] = df.vals.apply(lambda x: max(x) - min(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dates</th>\n",
       "      <th>vals</th>\n",
       "      <th>usage_val</th>\n",
       "      <th>user_lifetime</th>\n",
       "      <th>range_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DatetimeIndex(['2017-06-11', '2017-06-12', '20...</td>\n",
       "      <td>[11, 16, 12, 11, 10, 11, 12, 14]</td>\n",
       "      <td>8</td>\n",
       "      <td>9 days</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DatetimeIndex(['2017-06-11', '2017-06-12', '20...</td>\n",
       "      <td>[13, 6, 7, 9, 12, 10, 8]</td>\n",
       "      <td>7</td>\n",
       "      <td>7 days</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DatetimeIndex(['2017-06-12', '2017-06-13', '20...</td>\n",
       "      <td>[10, 10, 7, 13, 11, 12, 8, 10, 9]</td>\n",
       "      <td>9</td>\n",
       "      <td>8 days</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DatetimeIndex(['2017-06-13', '2017-06-20'], dt...</td>\n",
       "      <td>[7, 5]</td>\n",
       "      <td>2</td>\n",
       "      <td>7 days</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DatetimeIndex(['2017-06-18'], dtype='datetime6...</td>\n",
       "      <td>[10]</td>\n",
       "      <td>1</td>\n",
       "      <td>0 days</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               dates  \\\n",
       "0  DatetimeIndex(['2017-06-11', '2017-06-12', '20...   \n",
       "1  DatetimeIndex(['2017-06-11', '2017-06-12', '20...   \n",
       "2  DatetimeIndex(['2017-06-12', '2017-06-13', '20...   \n",
       "3  DatetimeIndex(['2017-06-13', '2017-06-20'], dt...   \n",
       "4  DatetimeIndex(['2017-06-18'], dtype='datetime6...   \n",
       "\n",
       "                                vals  usage_val user_lifetime  range_values  \n",
       "0   [11, 16, 12, 11, 10, 11, 12, 14]          8        9 days             6  \n",
       "1           [13, 6, 7, 9, 12, 10, 8]          7        7 days             7  \n",
       "2  [10, 10, 7, 13, 11, 12, 8, 10, 9]          9        8 days             6  \n",
       "3                             [7, 5]          2        7 days             2  \n",
       "4                               [10]          1        0 days             0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1     True\n",
       "2     True\n",
       "3    False\n",
       "4     True\n",
       "5     True\n",
       "6     True\n",
       "7     True\n",
       "8    False\n",
       "9    False\n",
       "Name: dates, dtype: bool"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identify users who provided input on a certain day\n",
    "# (maybe it's revealing that they did log something on Father's Day)\n",
    "df.dates.apply(lambda x: pd.Timestamp('2016-06-18').day in [d.day for d in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
